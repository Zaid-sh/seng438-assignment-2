**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#2 – Requirements-Based Test Generation**

| Group: 5      |
|-----------------|
| Mohammed Zaid Shaikh   |
| Alexander Lai          |
| Odin Fox               |
| Aidan Gaede-Janke      |

# 1 Introduction

This lab aims to generate unit test cases for the Range and DataUtilities classes provided in the JFreeChart framework. Before this lab, we had a basic understanding of black-box testing including methods such as Equivalence Class Testing, Boundary Value Testing, Robustness Testing, and Category-Partition Testing. Black box testing refers to testing a system without any knowledge of the internal structures or workings. This allows thorough testing of the input and output of the software without being biased by the code structure.

Our goal in this lab was to apply the fundamentals learned in class and apply automated unit testing using JUnit and JMock to test for the requirements of the system. We have achieved a working understanding of JUnit, implementing black box testing techniques, and using Javadoc to develop edge test cases.

# 2 Detailed description of unit test strategy

Range.class testing was the simplier of the two classes being tested. Nothing beyond simple assert() statements were used in the testing of it's methods. Combined with the simplicity of the class, the methods chosen to be tested were simple as well, only needing a few assert statements in most situations. Due to the simplicity, testing didn't have to be incredibly thorough, only having to worry about a handful of edge cases across all methods.

DataUtilities was much more difficult to program from a testing perspective. Mock classes did have to be utilized in order to thoroughly test DataUtilities. Specifically, mocks were used to create objects for Values2D and KeyedValues, so that we can simulate the exact behaviors without requiring actual implementation. With the added complexity of the class, along came many more test cases that had to be considered and accounted for. Certain inputs with null values, strings, and no values were tested extensively within these tests. 

# 3 Test cases developed

### **Range.class:**

boundGettersTest():     (Ensuring mix of decimal and integer double values)
-Intersecting ranges return true
-Ranges that do not overlap return false
-Check both above cases using decimal values
-Check that identical ranges return true
-Check if first range containing second range returns true, and vice versa

boundGettersTest():
-Check if lower bounds getter returns expected value with positive lower bound
-Check if lower bounds getter returns expected value with negative lower bound
-Check if upper bounds getter returns expected value with positive upper bound
-Check if upper bounds getter returns expected value with negative upper bound


### **DataUtilities.class:**

calculateColumnTotal(Values2D data, int column):
- values > 0 (positive inputs & numerical inputs)
- values == null (null input)
- values are string types (invalid input)

calculateRowTotal(Values2D data, int row):
- values > 0 (positive inputs)
- values < 0 (negative inputs)
- values == null (empty input)
- values are string types (invalid input)

createNumberArray(double[] data):
- data > 0 (positive array)
- data < 0 (negative array)
- data == null (empty array)

createNumberArray2D(double[][] data):
- data > 0 (positive array)
- data == {{}} (empty array)
- data == null (null value)

getCumulativePercentages(KeyedValues data):
- values > 0 (positive values)
- values < 0 (negative values)
- type(values) == String (String values)
- type(values) == null (null values)

// write down the name of the test methods and classes. Organize the based on
the source code method // they test. identify which tests cover which partitions
you have explained in the test strategy section //above

# 4 How the team work/effort was divided and managed

We split our group into two pairs, one group wrote and ran unit tests for DataUtilities, and the other wrote pair wrote and ran unit tests for
Range. Each class' methods were divded evenly (as possible) between the pair, each person designing and writing unit tests for each test case.
Once finished, each pair exchanged their tests amongst themselves for review. After that, the pairs exchanged their tests for their respective
class. Once all issues where sorted and everyone understood everyone else's testing, we collectively compiled our JUnit test suite.
Through this lab, we learned that having your unit tests pier reviewed as you write them mitigates the risk of erroneous testing or
inconsistencies. We also recognized that it was important everyone understood everyone else's unit tests to ensure a better baseline of
feedback when reviewing them.

# 5 Difficulties encountered, challenges overcome, and lessons learned

A difficulty that ocurred while working on this assignment was learning to use Jmock for the getcumulativepercentages. This was due to the repeated calling of the "keyedValues" class methods within getcumulativepercentages. We learned that use of the "allowed" tag over the "one" tag within Jmock makes the function usable multiple times. Another difficulty we faced was understanding the documentation about what would be considered invalid inputs. We systematically decided on what equivalent classes we would test to understand what was invalid or not.

# 6 Comments/feedback on the lab itself

Text…
